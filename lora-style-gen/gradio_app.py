import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

BASE_MODEL = "Qwen/Qwen2-0.5B-Instruct"
LORA_PATH = "./output_lora"

tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL,
    torch_dtype=torch.float16,
    device_map="auto"
)
model = PeftModel.from_pretrained(model, LORA_PATH)
model.eval()

def generate_xhs_text(features, temperature, max_tokens):
    prompt = f"è¯·æ ¹æ®å•†å“ç‰¹å¾å†™ä¸€æ®µå°çº¢ä¹¦é£æ ¼çš„æ–‡æ¡ˆï¼š\nå•†å“ï¼š{features}\næ–‡æ¡ˆï¼š"
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            temperature=temperature,
            do_sample=True,
            top_p=0.9
        )

    return tokenizer.decode(outputs[0], skip_special_tokens=True)

with gr.Blocks() as demo:
    gr.Markdown("# ğŸŒ¸ å°çº¢ä¹¦é£æ ¼æ–‡æ¡ˆç”Ÿæˆå™¨ï¼ˆLoRA å¾®è°ƒç‰ˆï¼‰")

    with gr.Row():
        features = gr.Textbox(label="å•†å“ç‰¹å¾", placeholder="ä¾‹ï¼šè“ç‰™è€³æœºï¼Œç»­èˆªé•¿ï¼Œä½©æˆ´èˆ’é€‚")
    
    with gr.Row():
        temperature = gr.Slider(0.2, 1.5, 0.7, label="Temperature")
        max_tokens = gr.Slider(50, 300, 150, label="Max New Tokens")

    result = gr.Textbox(label="ç”Ÿæˆæ–‡æ¡ˆ")

    submit_btn = gr.Button("ç”Ÿæˆæ–‡æ¡ˆ âœ¨")
    submit_btn.click(
        fn=generate_xhs_text,
        inputs=[features, temperature, max_tokens],
        outputs=result
    )

demo.launch(server_name="0.0.0.0", server_port=7860)

